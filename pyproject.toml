[build-system]
requires = ["setuptools>=70.0.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "plesk-unified"
version = "0.1.0"
description = "A unified MCP server that indexes and retrieves Plesk documentation using vector embeddings and semantic search with reranking"
readme = "README.md"
license = {text = "MIT"}
authors = [
    {name = "Gilson Siqueira", email = "gilson@example.com"}
]
keywords = ["plesk", "mcp", "model-context-protocol", "semantic-search", "rag", "vector-database"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Intended Audience :: System Administrators",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.12",
    "Programming Language :: Python :: 3.13",
    "Topic :: Documentation",
    "Topic :: System :: Monitoring",
    "Topic :: Utilities",
]
requires-python = ">=3.12"
dependencies = [
    "beautifulsoup4>=4.14.3",
    "fastmcp>=3.0.0",
    "gitpython>=3.1.46",
    "lancedb>=0.29.1",
    "sentence-transformers>=5.2.2",
    # Note: torch is already a dependency of sentence-transformers
    # For GPU support, install separately (see README)
]

[project.urls]
Homepage = "https://github.com/barateza/mcp-plesk-unified"
Documentation = "https://github.com/barateza/mcp-plesk-unified#readme"
Repository = "https://github.com/barateza/mcp-plesk-unified.git"
"Bug Tracker" = "https://github.com/barateza/mcp-plesk-unified/issues"

[tool.setuptools]
py-modules = ["server"]

[project.scripts]
# Console script to run the MCP server: `plesk-unified-mcp` will call `server:main`
plesk-unified-mcp = "server:main"

[tool.black]
line-length = 88
target-version = ["py312", "py313"]
include = '\.pyi?$'
extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | build
  | dist
  | __pycache__
)/
'''

[project.optional-dependencies]
# Note: torch is already a dependency of sentence-transformers
# For GPU support, install PyTorch with CUDA from https://pytorch.org/
# The server will automatically detect and use GPU acceleration if available.
dev = [
    "pytest>=8.0.0",
    "ruff>=0.3.0",
    "black>=24.0.0",
]
test = [
    "pytest>=8.0.0",
]

# --- NEW CONFIGURATION BELOW ---

[[tool.uv.index]]
name = "pytorch-cu124"
url = "https://download.pytorch.org/whl/cu124"
explicit = true

[tool.uv.sources]
torch = [
  { index = "pytorch-cu124", marker = "sys_platform == 'win32'" },
]
torchvision = [
  { index = "pytorch-cu124", marker = "sys_platform == 'win32'" },
]
torchaudio = [
  { index = "pytorch-cu124", marker = "sys_platform == 'win32'" },
]

[tool.isort]
profile = "black"
line_length = 88
known_first_party = ["knowledge_base", "plesk_unified"]

[tool.ruff]
line-length = 88
# Core runtime settings remain at top-level. Linter-specific selection
# options live under the `lint` table per ruff newer config layout.

[tool.ruff.lint]
select = ["E", "F", "W", "C90", "TC", "B", "B9"]
extend-ignore = ["E203"]
extend-select = []
